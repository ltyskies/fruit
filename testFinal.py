import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import os
import time
import numpy as np
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
import pandas as pd  # ç”¨äºç¾åŒ–ç»“æœè¾“å‡º
import torch.nn.functional as F


# --- 1. æ¨¡å‹å®šä¹‰ ---
print(torch.cuda.is_available())
class SimpleCNN(nn.Module):
    def __init__(self, num_classes):
        super(SimpleCNN, self).__init__()
        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)
        self.bn1 = nn.BatchNorm2d(16)
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)

        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)
        self.bn2 = nn.BatchNorm2d(32)

        self.fc1 = nn.Linear(8192, 128)
        self.fc2 = nn.Linear(128, num_classes)

    def forward(self, x):
        x = self.pool(F.relu(self.bn1(self.conv1(x))))
        x = self.pool(F.relu(self.bn2(self.conv2(x))))
        x = x.view(x.size(0), -1)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x


# --- 2. é…ç½®å’Œæ•°æ®åŠ è½½ ---

# æ³¨æ„ï¼šæ ¹æ®æ‚¨çš„æ–‡ä»¶ç»“æ„ï¼ŒTEST_DATA_ROOT åº”è¯¥æŒ‡å‘ test æ–‡ä»¶å¤¹
TEST_DATA_ROOT = 'data/workspace/test'

# å‡è®¾æ¨¡å‹å’Œé‡åŒ–æ¨¡å‹çš„æ–‡ä»¶å
ORIGINAL_MODEL_PATH = 'FruitNet_model.pth'
QUANTIZED_MODEL_PATH = 'FruitNet_model_quantized.pth'

# ç±»åˆ«ä¿¡æ¯ (åº”ä¸è®­ç»ƒè„šæœ¬ä¸­çš„åˆå¹¶ç»“æœä¸€è‡´)
CLASS_NAMES = ['Apple', 'Banana', 'Guava', 'Lemon', 'Orange', 'Pomegranate']
NUM_CLASSES = len(CLASS_NAMES)
IMAGE_SIZE = 64
BATCH_SIZE = 32
# åŸå§‹æ¨¡å‹åœ¨ GPU/CPUï¼Œé‡åŒ–æ¨¡å‹å¿…é¡»åœ¨ CPU
DEVICE_ORIGINAL = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
DEVICE_QUANTIZED = torch.device("cpu")  # é‡åŒ–æ¨¡å‹åªèƒ½åœ¨ CPU ä¸Šè¿è¡Œ

# æ•°æ®é¢„å¤„ç†
data_transforms = transforms.Compose([
    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# åŠ è½½æµ‹è¯•æ•°æ®é›† (ä½¿ç”¨æ ‡å‡†çš„ ImageFolderï¼Œå› ä¸ºå®ƒå·²ç»æŒ‰åˆå¹¶åçš„ç±»åˆ«ç»„ç»‡)
try:
    test_dataset = datasets.ImageFolder(
        root=TEST_DATA_ROOT,
        transform=data_transforms
    )
    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)
    print(f"æˆåŠŸåŠ è½½æµ‹è¯•æ•°æ®ã€‚æ€»æ ·æœ¬æ•°: {len(test_dataset)}")
except Exception as e:
    print(f"âŒ æ— æ³•åŠ è½½æµ‹è¯•æ•°æ®ã€‚è¯·æ£€æŸ¥è·¯å¾„ {TEST_DATA_ROOT} å’Œæ–‡ä»¶å¤¹ç»“æ„ã€‚é”™è¯¯: {e}")
    exit()

# æ£€æŸ¥æµ‹è¯•é›†ç±»åˆ«æ˜¯å¦ä¸é¢„æœŸåŒ¹é…
if sorted(test_dataset.classes) != sorted(['Apple', 'Banana', 'Guava', 'Lemon', 'Orange', 'Pomegranate']):
    print("âš ï¸ è­¦å‘Šï¼šæµ‹è¯•é›†ç±»åˆ«ä¸é¢„æœŸä¸å®Œå…¨åŒ¹é…ã€‚è¯·æ£€æŸ¥ Lemon æ˜ å°„ã€‚")
    print(f"æµ‹è¯•é›†æ£€æµ‹åˆ°çš„ç±»åˆ«: {test_dataset.classes}")
    # å¼ºåˆ¶ä½¿ç”¨è®­ç»ƒè„šæœ¬ä¸­çš„ CLASS_NAMESï¼Œä»¥ç¡®ä¿æ··æ·†çŸ©é˜µç»´åº¦æ­£ç¡®
    print(f"å°†ä½¿ç”¨è®­ç»ƒè„šæœ¬ä¸­çš„ç±»åˆ«åç§°: {CLASS_NAMES}")


# --- 3. æ¨¡å‹åŠ è½½å‡½æ•° ---

def load_model(path, is_quantized=False, device='cpu'):
    model = SimpleCNN(num_classes=NUM_CLASSES)

    if is_quantized:
        # 1. åŠ¨æ€é‡åŒ– (ä¸è®­ç»ƒè„šæœ¬ä¸­ä¿å­˜çš„æ–¹å¼åŒ¹é…)
        model = model.to('cpu')
        model_q = torch.quantization.quantize_dynamic(
            model,
            {nn.Conv2d, nn.Linear},
            dtype=torch.qint8
        )
        # 2. åŠ è½½é‡åŒ–æ¨¡å‹çš„ state_dict
        model_q.load_state_dict(torch.load(path))
        model_q.eval()
        return model_q.to(device)
    else:
        # åŸå§‹æ¨¡å‹åŠ è½½
        model.load_state_dict(torch.load(path, map_location=device))
        model.eval()
        return model.to(device)


# --- 4. æ ¸å¿ƒæµ‹è¯•å‡½æ•° ---

def test_model(model, loader, device, model_name):
    print(f"\n--- å¼€å§‹æµ‹è¯•æ¨¡å‹: {model_name} (åœ¨ {device}) ---")

    model.eval()
    all_preds = []
    all_labels = []
    total_time = 0.0

    # é¢„çƒ­ GPU (å¦‚æœä½¿ç”¨)
    if device.type == 'cuda':
        dummy_input = torch.randn(BATCH_SIZE, 3, IMAGE_SIZE, IMAGE_SIZE).to(device)
        _ = model(dummy_input)
        torch.cuda.synchronize()

    # æ­£å¼æ¨ç†
    with torch.no_grad():
        start_time = time.time()
        for inputs, labels in loader:
            inputs = inputs.to(device)
            labels = labels.cpu().numpy()

            # æ¨ç†
            outputs = model(inputs)
            _, predicted = torch.max(outputs.data, 1)

            all_preds.extend(predicted.cpu().numpy())
            all_labels.extend(labels)

        if device.type == 'cuda':
            torch.cuda.synchronize()  # ç¡®ä¿æ‰€æœ‰ GPU æ“ä½œå®Œæˆ

        end_time = time.time()
        total_time = end_time - start_time

    # --- æ€§èƒ½æŒ‡æ ‡è®¡ç®— ---

    # æ··æ·†çŸ©é˜µ
    cm = confusion_matrix(all_labels, all_preds)

    # æŸ¥å‡†ç‡ã€å¬å›ç‡ã€F1-score (ä½¿ç”¨ target_names=CLASS_NAMES)
    report = classification_report(all_labels, all_preds, target_names=CLASS_NAMES, output_dict=True, zero_division=0)

    # å‡†ç¡®ç‡
    accuracy = accuracy_score(all_labels, all_preds)

    # æ¨ç†æ—¶é—´ (ç§’/æ ·æœ¬)
    time_per_sample = total_time / len(all_labels)

    return {
        'model_name': model_name,
        'accuracy': accuracy,
        'cm': cm,
        'report': report,
        'total_time': total_time,
        'time_per_sample': time_per_sample,
    }


# --- 5. æ‰§è¡Œæµ‹è¯•å’Œå¯¹æ¯” ---

# 5.1. åŠ è½½å’Œæµ‹è¯•åŸå§‹æ¨¡å‹
try:
    original_model = load_model(ORIGINAL_MODEL_PATH, is_quantized=False, device=DEVICE_ORIGINAL)
    original_results = test_model(original_model, test_loader, DEVICE_ORIGINAL, "åŸå§‹æ¨¡å‹ (Full Precision)")
except Exception as e:
    print(f"\nâŒ åŸå§‹æ¨¡å‹æµ‹è¯•å¤±è´¥ã€‚è¯·ç¡®ä¿æ–‡ä»¶ {ORIGINAL_MODEL_PATH} å­˜åœ¨ã€‚é”™è¯¯: {e}")
    original_results = None

# 5.2. åŠ è½½å’Œæµ‹è¯•é‡åŒ–æ¨¡å‹
try:
    quantized_model = load_model(QUANTIZED_MODEL_PATH, is_quantized=True, device=DEVICE_QUANTIZED)
    quantized_results = test_model(quantized_model, test_loader, DEVICE_QUANTIZED, "é‡åŒ–æ¨¡å‹ (Quantized)")
except Exception as e:
    print(f"\nâŒ é‡åŒ–æ¨¡å‹æµ‹è¯•å¤±è´¥ã€‚è¯·ç¡®ä¿æ–‡ä»¶ {QUANTIZED_MODEL_PATH} å­˜åœ¨ã€‚é”™è¯¯: {e}")
    quantized_results = None

# --- 6. ç»“æœå¯¹æ¯”è¾“å‡º ---

print("\n" + "=" * 80)
print("             ğŸš€ æ¨¡å‹æ€§èƒ½å¯¹æ¯”æŠ¥å‘Š (æµ‹è¯•é›†) ğŸš€")
print("=" * 80 + "\n")

results = [original_results, quantized_results]
results = [r for r in results if r is not None]

if not results:
    print("æ²¡æœ‰å¯ç”¨çš„æµ‹è¯•ç»“æœè¿›è¡Œå¯¹æ¯”ã€‚")
    exit()

# 6.1. æ··æ·†çŸ©é˜µå¯¹æ¯”
for res in results:
    print(f"### {res['model_name']} - æ··æ·†çŸ©é˜µ (CM) ###")
    cm_df = pd.DataFrame(res['cm'], index=CLASS_NAMES, columns=CLASS_NAMES)
    print("--- é¢„æµ‹æ ‡ç­¾ (åˆ—) ---")
    print(cm_df)
    print("--- çœŸå®æ ‡ç­¾ (è¡Œ) ---\n")

# 6.2. æ±‡æ€»æŒ‡æ ‡è¡¨æ ¼

summary_data = []
for res in results:

    macro_avg = res['report']['macro avg']
    weighted_avg = res['report']['weighted avg']

    # é‡ç‚¹æŒ‡æ ‡æå–
    summary_data.append({
        'æ¨¡å‹': res['model_name'],
        # ä½¿ç”¨å·²ç»è®¡ç®—å¥½çš„æ•´ä½“å‡†ç¡®ç‡
        'å‡†ç¡®ç‡ (Accuracy)': f"{res['accuracy']:.4f}",
        'æŸ¥å‡†ç‡ (P_wtd)': f"{weighted_avg['precision']:.4f}",
        'å¬å›ç‡ (R_wtd)': f"{weighted_avg['recall']:.4f}",
        'F1-Score (wtd)': f"{weighted_avg['f1-score']:.4f}",
        'æ€»æ¨ç†æ—¶é—´ (s)': f"{res['total_time']:.4f}",
        'å¹³å‡æ¯æ ·æœ¬æ—¶é—´ (ms)': f"{res['time_per_sample'] * 1000:.4f}",
    })

summary_df = pd.DataFrame(summary_data)
summary_df.set_index('æ¨¡å‹', inplace=True)

print("### ğŸ“š å…³é”®æŒ‡æ ‡æ±‡æ€»å¯¹æ¯” ###")
print(summary_df)

print("\n" + "=" * 80)

# 6.3. åˆ†ç±»æŠ¥å‘Š (å¯é€‰ï¼Œæä¾›æ›´è¯¦ç»†çš„æ¯ç±»åˆ«æŒ‡æ ‡)
for res in results:
    print(f"\n### {res['model_name']} - è¯¦ç»†åˆ†ç±»æŠ¥å‘Š ###")
    report_df = pd.DataFrame(res['report']).transpose()
    # æ ¼å¼åŒ–è¾“å‡º
    print(report_df.applymap(lambda x: f"{x:.4f}" if isinstance(x, (float, np.float64)) else x))

print("=" * 80)